\documentclass{llncs}
\pagestyle{plain}
\usepackage{amsmath,amssymb,amsfonts,stmaryrd}
\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{color}
\usepackage{hyperref}
\usepackage[T1]{fontenc}
\usepackage{verbatim}
%\usepackage{algorithm}
\usepackage{float}

\newcommand{\wip}[1]{\textcolor{Purple}{WIPWIPWIPWIP #1 WIPWIPWIPWIP}}
\newcommand{\francois}[1]{\textcolor{blue}{#1}}
\newcommand{\sylvain}[1]{\textcolor{green}{#1}}

\newcommand{\defleq}{\sqsubseteq_{\text{def}}}
\newcommand{\lra}{\longrightarrow}

\floatstyle{ruled}
\newfloat{algorithm}{h}{algfig}
\floatname{algorithm}{Algorithm}

\begin{document}

\title{Probably Approximately Correct Learning of Regulatory Networks from Boolean Traces}

\author{Arthur Carcano\inst{1} \and Fran\c{c}ois Fages\inst{2} \and Sylvain
Soliman\inst{2}}

\institute{%
Ecole Normale Sup\'erieure, Paris, France\\
  \email{arthur.carcano@ens.fr}
\and Inria, University Paris-Saclay, Lifeware group, France\\
   \email{Francois.Fages@inria.fr},
   \email{Sylvain.Soliman@inria.fr}
}

\maketitle

\begin{abstract}
Automating the process of model building from experimental data 
is a very desirable goal to palliate the lack of modellers for many applications.
Despite the spectacular progress of machine learning techniques in data analytics, classification and clustering,
learning dynamical models from data time-series is challenging.
In this paper we investigate the use of the Probably Approximately Correct (PAC) learning 
framework of Leslie Valiant as a method for the automated discovery of Boolean influence models of biochemical processes from Boolean traces. 
We show that Thomas's Boolean influence systems can be naturally represented by k-CNF formulae
from Boolean transition samples with a quasi linear number of Boolean transition samples,
and that positive Boolean influence systems can be represented by monotone DNF formulae.
We evaluate PAC learning algorithms in this context on Boolean models of T-lymphocyte and MAPK signalling,
and discuss the merits of this framework and its limitations with respect to realistic experiments.
\end{abstract}

\section{Introduction}

Modeling biological systems is still an art which is currently limited in its applications by the number of available modelers.
Automating the process of model building is thus a very desirable goal
to attack new applications, develop patient-tailored therapeutics,
and also design experiments that can now be largely automated
with a gain in both the quantification and the reliability of the observations, at both the single cell and cell population levels.

Machine learning is revolutionizing the statistical methods in biological data analytics,
data classification and clustering, and prediction making.
However, learning dynamical models from data time-series is more challenging.
There has been early work on the use of machine learning techniques, such as inductive
 logic programming~\cite{Muggleton95ngc} combined with active learning in the vision of the ``robot scientist''~\cite{BMOKRK01etai},
to infer gene functions,
metabolic pathway descriptions~\cite{AM02etai,AM02slps}
or gene influence systems~\cite{BCRG04jtb},
or to revise a reaction model with respect to CTL properties~\cite{CCFS06tcsb}.
Since a few years, progress in this field can be measured on public benchmarks
of the ``Dream Challenge'' competition~\cite{Meyer14bmc}.
Logic Programming, and especially \emph{Answer Set Programming} (ASP), provide efficient tools such as CLASP~\cite{GKNS07lpnmr}
to implement learning algorithms for Boolean models.
They have been applied in~\cite{GSTUV08iclp} to the detection of  inconsistencies in large biological networks,
and have been subsequentially applied to the inference of gene networks from gene expression data and to the design of discriminant experiments \cite{VKASSSG15frontiers}.
Furthermore, ASP has been combined with CTL model-checking in~\cite{OPSSG16biosystems} to learn mammalian signalling networks from time series data,
and identify erroneous time-points in the data.

Budgeted learning extends active learning with a notion of cost for the calls to the oracle.
The original motivation for the budgeted learning protocol came from medical applications in which the outcome of a treatment,
drug trial, or control group is known, and the results of running medical tests are each available for a price~\cite{DZBSM13ml}.
In this context, multi-armed bandit methods~\cite{DBSSZ07icdm} provide the best strategies.
In~\cite{LMALS14ecml}, a bandit-based active learning algorithm is proposed for experiment design in dynamical system identification.

In this paper, we consider the Probably Approximately Correct (PAC) Learning 
framework of Leslie Valiant~\cite{Valiant84cacm},
and investigate its use as a method for the automated discovery of Boolean influence models of biochemical processes from Boolean traces. 
To the best of our knowledge, 
the application of PAC learning to Boolean models of biological systems has not been reported before.

We show that Thomas's gene regulatory networks \cite{Thomas91jtb,Thomas73jtb} can be naturally represented by 
Boolean formulae in conjunctive normal forms with a bounded number of litterals (i.e.~k-CNF formulae),
and can be learned from Boolean transition samples with a quasi linear number of Boolean transition samples, using Valiant's PAC learning algorithm for k-CNF formulae.
We also show that Boolean influence systems with their positive Boolean semantics discussed in \cite{FMRS16cmsb}
can be naturally represented by monotone DNF formulae.
Valiant's PAC active learning algorithm for monotone DNF formulae makes it possible in theory 
to learn a Boolean influence model from a set of positive examples and a set of calls to an oracle for the Boolean transitions.
However, ...

These results are illustrated in the following with a Boolean influence model of the lymphocyte T as running example.
They are further evaluated on... of size ...
We evaluate the PAC learning protocols first without prior knowledge, and then with knowledge of the unsigned or signed influence graph without Boolean functions.

We conclude on the merits of this framework, but also on its limits to scale up,
and to be usable in the context of a wet lab context for real biological experiment design.


\section{Preliminaries on PAC Learning}\label{pac}

In his seminal paper on a theory of the learnable~\cite{Valiant84cacm},
Valiant questioned what can be learned from a computational viewpoint,
and introduced the concept of probably approximate correct (PAC) learning,
together with a general-purpose polynomial-time learning protocol.
Beyond the learning algorithms that one can derive with this methodology,
Valiant's theory of the learnable has profound implications
on the nature of biological and cognitive processes,
of collective and individual behaviors,
and on the study of their evolution~\cite{Valiant13book}.
In this section, we simply recall the general theory of PAC learning,
and illustrate it with the learning of Boolean formulae.

\subsection{Definitions}

Let us consider a finite set of Boolean variables $x_1,\ldots,x_n$,
\begin{itemize}
	\item A vector is an assignment of the $n$ variables to $\mathbb{B} = \{0,1\}$
	\item A Boolean function $F:{\mathbb{B}}^n \rightarrow \mathbb{B}$
	assigns a Boolean value to each vector.
\end{itemize}

The idea behind the PAC learning protocol is to discover a hidden Boolean function $F$ while restricting oneself to the two following operations~:
\begin{itemize}
  \item
\textsc{Sample}$()$~: which returns a positive example, i.e.~a vector $v$ such that $F(v)=1$. 
The output of \textsc{Sample}$()$ follow a given probability distribution $D(v)$, which will be later used to measure the approximation of the result.
  \item
\textsc{Oracle}$(x)$~: which calls an oracle on some input $v$ to obtain the value of $F(v)$
\end{itemize}


\begin{definition}[Learnable class~\cite{Valiant84cacm}]
	\label{def:learnclass}
   A class $\cal M$ of \emph{Boolean functions} is said to be \emph{learnable}
   if there exists an algorithm $\cal A$ such that:
   \begin{itemize}
      \item $\cal A$ runs in polynomial time in $n$ -- the dimension of the models to learn -- and $h$ the precision parameter.
      \item
         For all functions $F$ in $\cal M$, and all distributions $D$ on the positive examples outputted by \textsc{Sample}$()$,
         $\cal A$ deduces with probability higher than $1-h^{-1}$ an approximation $G$ of $F$ in $\cal M$ such that
         \begin{itemize}
            \item $G(v)=1$ implies $F(v)=1$ (no false positives)
            \item
               $\sum_{v\ s.t.\ F(v)=1\wedge G(v)=0} D(v) < h^{-1}$ (false negative have a low probability to be sampled)
         \end{itemize}
   \end{itemize}
\end{definition}


\subsection{Boolean formulae}

Interestingly, Valiant showed the learnability of some important classes of functions in this framework,
in particular for Boolean formulae in conjunctive normal forms with at most $k$ literals per conjunct (k-CNF),
and for monotone (i.e.~negation free) Boolean formulae in disjunctive normal form (DNF).
The computational complexity of the PAC learning algorithms for these classes of functions is expressed in terms of the function
$L(h,S)$ defined as the smallest integer $i$ such that
in $i$ independent Bernoulli trials, each with probability at least $h^{-1}$ of success, the probability of having fewer than $S$ successes is less than $h^{-1}$.
Interestingly, this function is quasi-linear in $h$ and $S$, i.e.~for all
integers $S\ge 1$ and reals $h>1$, $L(h,S) \le 2h(S+\log_e h)$~\cite{Valiant84cacm},.

\begin{theorem}[\cite{Valiant84cacm}]\label{thm:kcnf}
First, for any $k$, the class of $k$-CNF formulae on $n$ variables is learnable with an
algorithm that uses $L(h,{(2 n)}^{k+1})$ examples and no oracle.
\end{theorem}

\begin{algorithm}
\begin{enumerate}
  \item Initialize $g$ to the conjunction of all possible disjunctions of at most $k$ literals (there are $O(n^k)$ such disjunctions),
\item Call $L(h,(2n)^{k+1})$ positive examples $v$, and for each $v$~:
\begin{itemize}
\item Delete all the disjunctions in $g$ that do not contain a literal true in $v$.	
\end{itemize}

\end{enumerate}
\caption{Algorithm for the PAC-learning of $k$-CNF formulae.\label{algCNF}}
\end{algorithm}

Algorithm \ref{algCNF} is used in the proof by Valiant. In this algorithm, the initialization of the learned function $g$ to the false constraint expressed as the conjunction of all possible disjunctions
leads to the learning of a minimal  generalization of the positive examples.


\begin{theorem}[\cite{Valiant84cacm}]\label{thm:mdnf}
    Second, the class of monotone DNF formulae n $n$ variables is also learnable with an
    algorithm that uses $L(h,d)$ examples and $d n$ calls to the oracle,
    \wip{where $d$ is the largest number of prime implicants in an equivalent prime DNF formula}~\cite{Valiant84cacm}.
\end{theorem}

Proof of this theorem relies on algorithm \ref{algDNF}. As previously, the algorithm guarantees that a minimal generalization is learned, up to the approximations previously defined.

\begin{algorithm}
\begin{enumerate}
\item Initialize $g$ with constant zero,
\item
Do $L(h,d)$ calls to positive examples $v$, and for each $v$,
\begin{itemize}
	\item 
	If $g$ is not implied by $v$, add the conjunction of determined literals that
	are essential to $f$ which is determined by $d n$ calls to the oracle.
\end{itemize}
\end{enumerate}
\caption{Algorithm for the PAC-learning of monotone DNF formulae.\label{algDNF}}
\end{algorithm}

\section{PAC Learning Gene regulatory Networks}

We will now investigate how PAC-learning, and the existing PAC learning algorithms for Boolean formulae,
can be applied to the
learnability of two different classes of Boolean models commonly used in
Systems Biology. First, we describe how PAC-learning applies to the
logical models \emph{\`a la} Thomas, describing gene regulatory networks in a
\emph{functional} way. Then we extend this approach to the positive Boolean semantics of influence systems, as described in~\cite{FMRS16cmsb}.

In both cases, we will assume, in this Section, that we do have perfect
\textsc{Sample} and \textsc{Oracle} functions.

\subsection{$k$-CNF Models of Thomas's Networks}

This Boolean framework perfectly fits the Boolean semantics of Thomas's gene
regulatory networks~\cite{Thomas73jtb}.

\begin{definition}
   A \emph{Thomas} network is defined by a set of genes $\{x_1,\dots,x_n\}$
   and $n$ Boolean functions $\{f_1,\dots,f_n\}$ describing for each gene its
   possible next state, given the current state.
\end{definition}

%Without loss of generality we will assume that the fuctions $f_i$ are given in
%CNF\@.


$k$-CNF formulae can be used to represent such gene regulatory network functions with some reasonable restrictions on their connectivity.
In particular, it is worth noticing that in Thomas networks of degree bounded by $k$,
each gene has at most $k$ regulators, each gene activation function $f_i$ thus depends of at most $k$ variables
and can certainly be represented by a $k$-CNF formula.

In this case, the algorithm \ref{algCNF} is repeated $n$ times in order to learn each of the $f_i$.

\begin{example}
   Running example?
\end{example}



\subsection{Monotone DNF Models of Influence Systems}

Influence systems with forces have been introduced in \cite{FMRS16cmsb} 
to provide influence systems \emph{\`a la} Thomas with a hierarchy of semantics
including the differential, stochastic, Petri Net and Boolean semantics.
The approximation and abstraction relationships that link those different interpretations of a same influence system,
lead us to consider the positive semantics of influence systems,
which do contain positive and negative influences but no influence inhibitors, i.e.~no negation in the conditions
for applying the influence in the Boolean semantics \cite{FMRS16cmsb}.
In this section we restrict ourselves to the positive semantics of influence systems
and syntactically to influence systems without inhibitors.

\begin{definition}

   An \emph{influence system} (without inhibitor) $I$ on a set of variables $S=\{x_1,\dots,x_n\}$ is a
   finite set of quadruples $(P, t, \sigma, f)$, called \emph{influences}, where
   $P\subset S$ is called the set of \emph{positive sources} of the influence,
%   $N\subset S$ \emph{negative sources}, 
$t\in S$ is the \emph{target} of the influence,
   $\sigma\in\{+,-\}$ is its \emph{sign positive or negative}, and $f$ is a
   real-valued mathematical function $P\to\mathbb{R^+}$, called the
   \emph{force} of the influence.

\end{definition}

\begin{definition}[Positive Boolean Semantics]
The positive Boolean semantics of an influence system $\{(P_i, t_i, \sigma_i, f_i)\}_{i\in I}$
over a set $S$ of $n$ variables,
is the Boolean transition system $\lra$ defined over Boolean state vectors in $\mathbb{B}^n$
by
${\vec x}\lra{\vec x'}$ if there exists an influence $(P_i, t_i, \sigma_i, f_i)$
such that ${\vec x}\models \bigwedge_{p\in P_i}$
and ${\vec x'} = {\vec x}\ \sigma_i\ t_i$.
\end{definition}


  % These Boolean functions are best represented by Boolean concepts in PAC terminology
  % in order to make explicit the independent genes.
  % Then, the problem of building such a Boolean model is to give for each gene
  % two Boolean activation and deactivation functions that are compatible with the observed temporal data of gene activation.
% It is worth noticing that the PAC learning protocol makes it possible to learn such Boolean models of gene regulation
% not only from a given finite set of positive gene activation observations,
% but also from new biological experiments designed by the PAC learning algorithm itself.

% \sylvain{interesting but out of place}


\section{In practice application of PAC-learning of $k$-CNF}


In order to make use of this learning algorithm on real data, a first step is
to assume that we do not have full access to the hidden Boolean function for
\textsc{Sample} and \textsc{Oracle}, but to restrict ourselves to the observations that can be obtained from data time-series.

This has two major consequences: the first one is that we lose oracles
completely. We will discuss in Section~\ref{sec:oracles} how to recover them
by some kind of experiment design, but in the current section we will assume
that no oracle is available. One immediate corollary is that the existing
algorithm for DNF formulae is not available to us any longer.

The other consequence is that instead of a pure sampling of the state-space to
obtain examples, we will restrict ourselves to samples obtained by traces.
From now on, we can hence no longer pretend to recover Ã  la Thomas networks but we will instead focus on finding the activation and deactivation functions for each genes, which are defined below.

\begin{definition}
 	Given a network of $n$ genes $x_1,\ldots,x_n$, and
 	an integer $1 \leq k \leq n$ we can define ${x_k}_+$ (resp.\ ${x_k}_-$):
 	${\{0,1\}}^n \rightarrow\{0,1\}$ the activation (resp.\ deactivation)
 	Boolean function of $x_k$. In a given state $v$, ${x_k}_+(v)$ (resp.\ ${x_k}_-$(v)) is worth 1 if and only if the gene $x_k$ can be activated (resp. deactivated) from state $v$.
\end{definition}

To this end, we consider that a positive example for an (resp. de-)activation function is simply a state from which the direct next step was the (resp. de-)activation of the gene.



\subsection{PAC Learning from Boolean Traces}

A first experimentation was to simulate boolean traces for a given influence network, and use them as a basis to learn. A toy example is given in figure \ref{bool-LV} (influence network) and the correspondign results are presented in figures \ref{bool-LV.res} and \ref{bool-LV.res.pretty}

Output is to be read as follow:\\
\texttt{Foo+:~[['A','Z'],~['!E'],~['!Foo']]} means that the activation (\texttt{+}) function of B is $(A \vee Z)\wedge\neg E$. Remark that to be activated, Foo obviously needed to be deactivated first.

\subsubsection{Results}

\begin{figure}[htp]
	\verbatiminput{examples/bool-lokta.reac}
	\vspace{-1em}
	\caption{An influence system describing the Lokta-Voltera prey vs. predator model. Numbers in parenthesis indicate the force of an influence. \label{bool-LV}}
\end{figure}
\begin{figure}[htp]
	\verbatiminput{examples/bool-lokta.res}
	\vspace{-1em}
	\caption{Results of PAC-learning on traces of the Boolean simulation of the Lokta-Voltera toy example.\label{bool-LV.res}}
\end{figure}
\begin{figure}[htp]
	\ttfamily
	Predator+: $False$
	
	Predator-: Predator $\wedge$ (no Prey)
	
	Prey+: $False$
	
	Prey-: Predator $\wedge$ Prey
	\rmfamily
	\caption{Prettified results of PAC-learning on traces of the Boolean simulation of the Lokta-Voltera toy example.\label{bool-LV.res.pretty}}
\end{figure}
\pagebreak
The results can be interpreted as follow:

Both the predator and the prey species cannot appear. It is important to note that the activation functions in the Lokta Voltera models means the apparition on extinction of the species as a whole and not of individuals of it.

For the predator to disappear, it is necessary that there is predator in the first place and that there is no prey. If the first part of this conjunction is obviously true, the second is false: strictly speaking, predators may disappear even if there is prey left, yet this case is very unlikely: the most likely case is that the predator will go extinct only once there are no more preys left for it to eat. This is a good example of how the learning is only approximate.

Finally, for the prey to go extinct, there must be both prey in the first place and predator to eat it. This is true.

\subsubsection{On the quantification of the approximation}

As it can be seen even on this very simple example, the "approximately" in "probably approximately correct" is not there for nothing. Yet, as explained in definition \ref{def:learnclass}, the quantification of this approximation relies on the knowledge of the distributions of the samples.

Even though we were not able to write it down exactly, it is our conjecture that in the present case, the probability of a positive example $v$ of (de)activation function $x\pm$ to be sampled is strongly and intuitively correlated to both the probability that the system reaches state $v$ and the probability of the actual (de)activation of gene $x$ from state $v$. 



\subsection{PAC Learning from Stochastic Traces}

In order to push our experiments even further, we shall now produce the trace
data, not directly from a Boolean model, but from more realistic simulations.

For the sake of evaluating the learning algorithm,
we simulate wet lab experiments \emph{in silico}, using Gillespie's algorithm for stochastic simulation.
This stochastic semantics gave us traces in ${\mathbb{N}}^n$ that we abstract as traces in ${\{0,1\}}^n$.

%Our simulator uses a custom language to specify experiments and allows us to set the amount of each species before the experiment is run. The number of run is given by Valiant's bound on the number of sampling calls.


We ran two example reactions, given in figures~\ref{test}, and \ref{preypred}.

\begin{figure}[htbp]
	\verbatiminput{examples/test.reac}
	\vspace{-1em}
	\caption{A test reaction, A and E appear naturally in the medium, and A can be turned into B in absence of E. B  can be turned into C. All of the species can disappear due to dilution.\label{test}}
\end{figure}
\begin{figure}[htbp]
	\verbatiminput{examples/lokta.reac}
	\vspace{-1em}
	\caption{A Prey-Predator model. The first line indicates the starting quantities for each species. This corresponds to the influence model given in figure \ref{bool-LV}.\label{preypred}}
\end{figure}

The first example gave perfect results, as indicated on figure~\ref{test_res}.
\begin{figure}
	\verbatiminput{examples/test.result}
	\caption{Results for the test example\label{test_res}}
\end{figure}

As previously, the prey-predator example (figure~\ref{preypred_res}) displays a typical error: because there is more than 1 prey, in the Gillespie algorithm, eating of a prey by a predator is way more likely than the death of old age of a predator, and hence the deactivation (ie extinction) of predators happen only when they cannot eat anymore and the only possible reaction is the third: death. This lead the learning algorithm to believe that the absence of prey is needed for extinction.
\begin{figure}
	\verbatiminput{examples/lokta.result}
	\caption{Results for the Prey-Predator model\label{preypred_res}}
\end{figure}
\subsection{PAC learning with hints}
All the systems proposed so far were of humble size. An actual influence system of bigger dimensions is the one that governs the differentiation of the lymphocyte T, as described by R\'{e}mi, Ruet and Thieffry\cite{RRMTC06tcsb}. Its description is given figure \ref{lympho} (page \pageref{lympho}).

\begin{figure}[htbp]
	\verbatiminput{examples/lympho-bool.reac}
	\vspace{-1em}
	\caption{The Th lymphocyte differentiation model of~\cite{RRMTC06tcsb}.\label{lympho}}
\end{figure}
However, results of learning on the traces resulting from the boolean simulation of this system gave very poor results (figure \ref{lympho_res}). Thankfully, the PAC learning algorithm for $k$-CNF can be modified to be able to take hints into account.

\wip{explain hints}

After supplying hints indicated in figure \ref{hints}, the results (figure \ref{hints.res}) are \wip{good}.
	
\begin{figure}
	\verbatiminput{examples/lympho_edited.result}
	\caption{Results for lymphocite model, edited. Lines with MISS are one on which the algorithm is too far. The tautological negation (\texttt{!A} for \texttt{A+}) have also been deleted.\label{lympho_res}}
\end{figure}

However, when given hints on the possible relations, as indicated in figure \ref{hints}, results (given figure~\ref{res_hints}) are correct.

\begin{figure}
	\verbatiminput{examples/lympho.hints}
	\caption{Hints for the lymphocyte model. For each species, a set of possible influencers is given. The PAC algorithm will then learn a model in which only the specified influencers can either induce or inhibit the species.\label{hints}}
\end{figure}
\begin{figure}
	\verbatiminput{examples/lympho-bool.res}
	\caption{Results for lymphocite model, with hints.\label{hints.res}}
\end{figure}

\subsection{Notes on the implementation}

Our implementation of the PAC-learning algorithm represents the lattice of $k$-clauses ordered by implication, thus allowing:
\begin{itemize}
	\item $O(1)$ access to any $k$-clause
	\item From clause $a$, $O(1)$ access to the smallest clauses implied by $a$ and to the biggest clauses that implies $a$
\end{itemize}
\section{Active Learning of Positive Influence Systems}
\label{sec:oracles}

\sylvain{I guess this is where the oracle as experiment-design discussion will
take place\dots}

The (positive) Boolean semantics of biochemical influence systems
can be directly represented by the disjunction of the (positive) enabling conditions of each, either positive or negative, influence on a given target,
i.e.~by a monotone DNF formula for each activation or inhibition of each target.
In the Lotka-Volterra influence system, the algorithm above is thus expected to learn the structure of the influence system
(without the stochiometry of course),
from the observation that the prey can disappear only in presence of the predator
while the predator can always disappear in presence or absence of the prey.

  Learning reaction models from observed transitions is much more tricky,
  since some reactions may change the Boolean value of several reactants or products in one single transition.
%  Let us first remark that the transition relation $r(x_1,\ldots,x_n,x'_1,\ldots,x'_n)$
%  is naturally represented in DNF by the disjunction of the conjunctions associated to each reaction
%  (remember that there can be several Boolean transitions associated to one reaction for taking
%into account the possibly partial or total consumption of the reactants).
%  is monotonic in the predecessor variables $x_i$'s in the postive Boolean semantics of reactions.
%  Furthermore it is also monotonic in the successor variables $x'_j$ since we consider
%  all partial or total consumptions of reactants.
  Therefore, it is not only the activation and inhibition functions of each species which are to be learnt,
  but the update functions of pairs and triples of species if we restrict to elementary reactions with at most two reactants or products.
  In this case, the update functions can be represented by monotonic DNF formulae, since the (positive) Boolean semantics of a reaction system does not test the absence.
Furthermore,   one cannot expect to learn the structure of such a reaction network
from the observation of the state transitions from one single initial state.
The learning algorithms assumes that the positive examples of the state transition relation be distributed
among the whole vector space.
For instance, in the MAPK example, in addition to the initial state of the wild type organism where all the kinases and phosphatases are present,
it is necessary to consider some mutated organisms, in which some kinases or phosphatases are absent,
in order to gain information on the precise conditions of activation and deactivation of the different forms of the kinases.
This strategy is essentially similar to what the biologists do to elucidate the structure of biological processes
in a qualitative manner.


\section{Conclusion and perspectives}

In conclusion, we have shown that Valiant's work on PAC learning seems to be a promising trail to serve as a way to automatically discover the underlying gene networks of a system, given precise traces of its run.

Moreover, PAC learnign can already efficiently leverage available prior knowledge on the system to deliver results even when dimensions increase.

Finally, the framework for monotone DNF seems to imply some experimental design that may be of interest to create an online learning algorithm.

Yet, our work present no comparison to ASP on common benchmark, nor comparison to budgeted learning, and the we may still lack the needed technology in biology for applicability to real biological experiments.

\bibliographystyle{splncs03}
\bibliography{contraintes}

\end{document}
